{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOXwy4JqP11nA0452Hdh6tS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"id":"fk9sDA2KiFBF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729744990550,"user_tz":-480,"elapsed":8317,"user":{"displayName":"Keith Chan","userId":"11054371261221442272"}},"outputId":"07d77192-8a0c-476a-d4bf-7a90044892f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\n","-------------------------------------------------------------------\n","Size of training data: (4517, 33)\n","Outliers found: (452, 33)\n","Size of Cleaned X: (4065, 33)\n","\n","-------------------------------------------------------------------\n","Original Dataset Shape: mortality\n","0.0    3084\n","1.0     981\n","Name: count, dtype: int64\n","\n","Resampled Dataset Shape: mortality\n","1.0    3084\n","0.0    3084\n","Name: count, dtype: int64\n","\n","-------------------------------------------------------------------\n","\n","Accuracy with class weights balanced: 0.74\n","\n","-------------------------------------------------------------------\n","\n","Classification Report with class weights balanced (0 - Alive / 1 - Dead):\n","\n","\n","              precision    recall  f1-score   support\n","\n","         0.0       0.80      0.87      0.83       850\n","         1.0       0.45      0.33      0.38       280\n","\n","    accuracy                           0.74      1130\n","   macro avg       0.62      0.60      0.61      1130\n","weighted avg       0.71      0.74      0.72      1130\n","\n","\n","ROC-AUC Score with class weights balanced: 0.68\n"]}],"source":["from google.colab import drive # Loading the Dataset\n","from datetime import datetime # Date & Time Manipulation\n","import pytz #Timezone Calculations\n","\n","import pandas as pd\n","import os\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n","\n","from sklearn.compose import ColumnTransformer # Pipeline\n","from sklearn.impute import SimpleImputer # Pipeline\n","from sklearn.ensemble import RandomForestClassifier, IsolationForest # Pipeline\n","from sklearn.linear_model import LogisticRegression # Pipeline\n","from sklearn.pipeline import Pipeline, make_pipeline # Pipeline\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler # Pipeline\n","\n","import numpy as np # Data Imputation\n","from sklearn.impute import KNNImputer # KNN Imputation\n","from imblearn.over_sampling import SMOTE # Data Imputation\n","from collections import Counter # Data Imputation\n","\n","from scipy.stats import chi2 # Checking for Outliers by Mahalanobis Distance\n","\n","drive.mount('/content/drive')\n","file_path = '/content/drive/My Drive/COMP7015 AI Project Group/mimiciv_traindata.csv'\n","print ('\\n-------------------------------------------------------------------')\n","df = pd.read_csv(file_path)\n","\n","# KNN Imputation (Imputation for Missing Value)\n","knn_imputer = KNNImputer(n_neighbors=3)\n","df_imputed = knn_imputer.fit_transform(df)\n","\n","# Convert the result back to a DataFrame\n","df_imputed = pd.DataFrame(df_imputed, columns=df.columns)\n","\n","# Features & Target\n","X = df_imputed[[\n","    'Fraction inspired oxygen_mean', 'Fraction inspired oxygen_min', 'Fraction inspired oxygen_max', \\\n","    'Glucose_mean', 'Glucose_min', 'Glucose_max', \\\n","    'Heart Rate_mean', 'Heart Rate_min', 'Heart Rate_max',\\\n","    'Mean blood pressure_mean', 'Mean blood pressure_min', 'Mean blood pressure_max', \\\n","    'Diastolic blood pressure_mean', 'Diastolic blood pressure_min', 'Diastolic blood pressure_max',\\\n","    'Systolic blood pressure_mean', 'Systolic blood pressure_min', 'Systolic blood pressure_max',\\\n","    'Oxygen saturation_mean', 'Oxygen saturation_min', 'Oxygen saturation_max',\\\n","    'Respiratory rate_mean', 'Respiratory rate_min', 'Respiratory rate_max',\\\n","    'Temperature_mean', 'Temperature_min', 'Temperature_max',\\\n","    'Weight_mean', 'Weight_min', 'Weight_max',\\\n","    'pH_mean', 'pH_min', 'pH_max']]\n","y = df_imputed['mortality']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Outlier Detection with Isolation Forest\n","iso_forest = IsolationForest(contamination=0.1, random_state=42)\n","iso_forest.fit(X_train)\n","\n","# Predict Outliers (-1 for outlier, 1 for inlier)\n","iso_outlier_predictions = iso_forest.predict(X_train)\n","\n","# Identify Outliers\n","outliers = X_train[iso_outlier_predictions == -1]\n","\n","# Display Original Data Size and Outliers Found\n","print (f'Size of training data: {X_train.shape}')\n","print (f'Outliers found: {outliers.shape}')\n","\n","# Remove Outliers from the Training Data\n","X_train_cleaned = X_train[iso_outlier_predictions == 1]\n","y_train_cleaned = y_train[iso_outlier_predictions == 1]\n","\n","print(f'Size of Cleaned X:', X_train_cleaned.shape)\n","\n","# Applying SMOTE (Oversampling Technique)\n","smote = SMOTE(random_state = 42)\n","X_resampled, y_resampled = smote.fit_resample(X_train_cleaned, y_train_cleaned)\n","print ('\\n-------------------------------------------------------------------')\n","print('Original Dataset Shape:', y_train_cleaned.value_counts())\n","print('\\nResampled Dataset Shape:', y_resampled.value_counts())\n","\n","# Create a pipeline\n","pipe = Pipeline([\n","        ('scaler', StandardScaler()), # Standardizes Features\n","        ('classifier', RandomForestClassifier(class_weight='balanced'))\n","                ])\n","\n","# Fit the pipeline to the resampled training data\n","pipe.fit(X_resampled, y_resampled)\n","\n","# Make predictions on the test set\n","y_pred = pipe.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print ('\\n-------------------------------------------------------------------')\n","print(f'\\nAccuracy with class weights balanced: {accuracy:.2f}')\n","\n","# Print classification report (includes precision, recall, and F1 score)\n","print ('\\n-------------------------------------------------------------------')\n","print('\\nClassification Report with class weights balanced (0 - Alive / 1 - Dead):')\n","print('\\n')\n","print(classification_report(y_test, y_pred))\n","\n","# Calculate and print ROC-AUC score\n","y_pred_proba = pipe.predict_proba(X_test)[:, 1]  # Get predicted probabilities for the positive class\n","roc_auc = roc_auc_score(y_test, y_pred_proba)\n","print(f'\\nROC-AUC Score with class weights balanced: {roc_auc:.2f}')"]}]}