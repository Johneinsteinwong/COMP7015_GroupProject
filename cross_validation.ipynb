{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from Models import probitModel, logisticModel\n",
    "from util import *\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import *\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import Memory\n",
    "from shutil import rmtree\n",
    "\n",
    "from sklearn.metrics import get_scorer\n",
    "from datetime import datetime\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='lightgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "\n",
    "data_folder = 'data'\n",
    "df = pd.read_csv(os.path.join(data_folder,'mimiciv_traindata.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('mortality',axis=1)\n",
    "y = df.mortality.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.mortality.value_counts(normalize=True))\n",
    "df.mortality.value_counts(normalize=True).plot(kind='bar')\n",
    "#sns.countplot(x='mortality', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV for weight of weighted loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probit_pipeline = [\n",
    "    ('scaler', QuantileTransformer(output_distribution='normal', ignore_implicit_zeros=False)),\n",
    "    ('imputer', KNNImputer(missing_values=np.nan, n_neighbors=10)),\n",
    "    ('model',probitModel()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(probit_pipeline)\n",
    "param_grid = {\n",
    "    'model__w': np.arange(0.1,1.0,0.05),\n",
    "}\n",
    "search = GridSearchCV(pipe, param_grid, cv=5, scoring=make_scorer(f1_score), n_jobs=-1, verbose=3)\n",
    "search.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_pipeline = [\n",
    "    ('scaler', QuantileTransformer(output_distribution='normal', ignore_implicit_zeros=False)),\n",
    "    ('imputer', KNNImputer(missing_values=np.nan, n_neighbors=10)),\n",
    "    ('model', logisticModel()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(probit_pipeline)\n",
    "param_grid = {\n",
    "    'model__w': np.arange(0.1,1.0,0.05),\n",
    "}\n",
    "search = GridSearchCV(pipe, param_grid, cv=5, scoring=make_scorer(f1_score), n_jobs=-1, verbose=3)\n",
    "search.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probit_cv(l1, l2):\n",
    "    probit_pipeline = [\n",
    "        ('scaler', QuantileTransformer(output_distribution='normal', ignore_implicit_zeros=False)),\n",
    "        ('imputer', KNNImputer(missing_values=np.nan, n_neighbors=10)),\n",
    "        ('model',probitModel( l1=l1, l2=l2, w=0.75 )),\n",
    "    ]\n",
    "\n",
    "\n",
    "    mean_score = cv(probit_pipeline, x.values, y, f1_score, 5, random_state=SEED)\n",
    "\n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo = BayesianOptimization(\n",
    "    probit_cv, \n",
    "    pbounds={\n",
    "        'l1':(0,5),\n",
    "        'l2':(0,5),\n",
    "    },                              \n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "bo.maximize(init_points=3, n_iter=100)\n",
    "\n",
    "time_elapsed = datetime.now() - start\n",
    "\n",
    "print('Time elapsed:',time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bo.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_cv(l1, l2):\n",
    "\n",
    "    logistic_pipeline = [\n",
    "        ('scaler', QuantileTransformer(output_distribution='normal', ignore_implicit_zeros=False)),\n",
    "        ('imputer', KNNImputer(missing_values=np.nan, n_neighbors=10)),\n",
    "        ('model', logisticModel(l1=l1, l2=l2, w=0.75)),\n",
    "    ]\n",
    "\n",
    "    mean_score = cv(logistic_pipeline, x.values, y, f1_score, 5, random_state=SEED)\n",
    "\n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo = BayesianOptimization(\n",
    "    logistic_cv, \n",
    "    pbounds={\n",
    "        'l1':(0,5),\n",
    "        'l2':(0,5),\n",
    "    },                              \n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "bo.maximize(init_points=3, n_iter=100)\n",
    "\n",
    "time_elapsed = datetime.now() - start\n",
    "\n",
    "print('Time elapsed:',time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bo.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def lightgbm_cv(\n",
    "        max_depth, num_leaves, \n",
    "        min_data_in_leaf, bagging_fraction, \n",
    "        feature_fraction, lambda_l1, lambda_l2,\n",
    "        min_split_gain, max_bin, drop_rate, max_drop\n",
    "    ):\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": None,\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"dart\",#\"gbdt\", #\n",
    "        \"is_unbalance\": True,\n",
    "        \"num_boost_round\": 1000,\n",
    "        \"learning_rate\" : 0.03,\n",
    "\n",
    "        \"max_depth\" : int(max_depth),\n",
    "        \"num_leaves\" : int(num_leaves),\n",
    "        \"min_data_in_leaf\": int(min_data_in_leaf),\n",
    "        \"bagging_fraction\": bagging_fraction,\n",
    "        \"feature_fraction\": feature_fraction,\n",
    "        \"lambda_l1\": lambda_l1,\n",
    "        \"lambda_l2\": lambda_l2,\n",
    "        \"min_split_gain\": min_split_gain,\n",
    "        \"max_bin\": int(max_bin),\n",
    "        # dart param\n",
    "        \"drop_rate\": drop_rate,\n",
    "        \"max_drop\": int(max_drop)\n",
    "    }\n",
    "\n",
    "    lightgbm_pipeline = [\n",
    "        ('scaler', QuantileTransformer(output_distribution='normal', ignore_implicit_zeros=False)),\n",
    "        #('imputer', KNNImputer(missing_values=np.nan, n_neighbors=10)),\n",
    "        ('model', LGBMClassifier(**params)),\n",
    "    ]\n",
    "\n",
    "    mean_score = cv(lightgbm_pipeline, x.values, y, f1_score, 5, random_state=SEED)\n",
    "\n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo = BayesianOptimization(\n",
    "    lightgbm_cv, \n",
    "    pbounds={\n",
    "        \"max_depth\" : (3, 10),\n",
    "        \"num_leaves\" : (20, 100),\n",
    "        \"min_data_in_leaf\": (1, 50),\n",
    "        \"bagging_fraction\": (0.5, 1.0),\n",
    "        \"feature_fraction\": (0.5, 1.0),\n",
    "        \"lambda_l1\": (0, 10),\n",
    "        \"lambda_l2\": (0, 10),\n",
    "        \"min_split_gain\": (0, 0.1),\n",
    "        \"max_bin\": (50,255),\n",
    "        # dart param\n",
    "        \"drop_rate\": (0,0.5),\n",
    "        \"max_drop\": (10,50)\n",
    "    },                              \n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "bo.maximize(init_points=3, n_iter=100)\n",
    "\n",
    "time_elapsed = datetime.now() - start\n",
    "\n",
    "print('Time elapsed:',time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_pipeline = [\n",
    "    ('scaler', QuantileTransformer(output_distribution='normal', ignore_implicit_zeros=False)),\n",
    "    ('imputer', KNNImputer(missing_values=np.nan, n_neighbors=10)),\n",
    "    ('model', logisticModel()),\n",
    "]\n",
    "logistic_pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
