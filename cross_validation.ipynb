{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from Models import probitModel, logisticModel\n",
    "from util import *\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import *\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import Memory\n",
    "from shutil import rmtree\n",
    "\n",
    "from sklearn.metrics import get_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "\n",
    "data_folder = 'data'\n",
    "df = pd.read_csv(os.path.join(data_folder,'mimiciv_traindata.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('mortality',axis=1)\n",
    "y = df.mortality.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.mortality.value_counts(normalize=True))\n",
    "df.mortality.value_counts(normalize=True).plot(kind='bar')\n",
    "#sns.countplot(x='mortality', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV for weight of weighted loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "probit_pipeline = [\n",
    "    #('scaler', RobustScaler(unit_variance=True)),\n",
    "    #('scaler', QuantileTransformer(output_distribution='normal', ignore_implicit_zeros=False)),\n",
    "    ('scaler', PowerTransformer(method='yeo-johnson', standardize=True)),\n",
    "    #('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    ('imputer', KNNImputer(missing_values=np.nan, n_neighbors=10)),\n",
    "   # ('smote', SMOTE(random_state = SEED)),\n",
    "    ('model',probitModel()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(probit_pipeline)\n",
    "param_grid = {\n",
    "    'model__w': np.arange(0.1,1.0,0.05),\n",
    "}\n",
    "search = GridSearchCV(pipe, param_grid, cv=5, scoring=make_scorer(f1_score), n_jobs=-1, verbose=3)\n",
    "search.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_pipeline = [\n",
    "    #('scaler', RobustScaler(unit_variance=True)),\n",
    "    #('scaler', QuantileTransformer(output_distribution='normal', ignore_implicit_zeros=False)),\n",
    "    ('scaler', PowerTransformer(method='yeo-johnson', standardize=True)),\n",
    "    #('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    ('imputer', KNNImputer(missing_values=np.nan, n_neighbors=10)),\n",
    "   # ('smote', SMOTE(random_state = SEED)),\n",
    "    ('model', logisticModel()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(probit_pipeline)\n",
    "param_grid = {\n",
    "    'model__w': np.arange(0.1,1.0,0.05),\n",
    "}\n",
    "search = GridSearchCV(pipe, param_grid, cv=5, scoring=make_scorer(f1_score), n_jobs=-1, verbose=3)\n",
    "search.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probit_cv(l1, l2):\n",
    "    probit_pipeline = [\n",
    "        #('scaler', RobustScaler(unit_variance=True)),\n",
    "        #('scaler', QuantileTransformer(output_distribution='normal', ignore_implicit_zeros=False)),\n",
    "        ('scaler', PowerTransformer(method='yeo-johnson', standardize=True)),\n",
    "        #('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "        ('imputer', KNNImputer(missing_values=np.nan, n_neighbors=10)),\n",
    "    # ('smote', SMOTE(random_state = SEED)),\n",
    "        ('model',probitModel( l1=l1, l2=l2, w=0.75 )),\n",
    "    ]\n",
    "\n",
    "\n",
    "    mean_score = cv(probit_pipeline, x.values, y, f1_score, 5, random_state=SEED)\n",
    "\n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bo = BayesianOptimization(\n",
    "    probit_cv, \n",
    "    pbounds={\n",
    "        'l1':(0,5),\n",
    "        'l2':(0,5),\n",
    "    },                              \n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "xgb_bo.maximize(init_points=3, n_iter=100)\n",
    "\n",
    "time_elapsed = datetime.now() - start\n",
    "\n",
    "print('Time elapsed:',time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
